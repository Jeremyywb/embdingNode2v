{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 选择维度作图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import NMF\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "import sys\n",
    "\n",
    "his_trans = pd.read_csv('../data/historical_transactions.csv')\n",
    "his_trans = his_trans[[ 'card_id','merchant_id' ]]\n",
    "cacheRoot = '../cache/'\n",
    "def create_edgelist(useData, dataID ,secNodeCol):\n",
    "    le = LabelEncoder()\n",
    "    datacp = useData[[dataID,secNodeCol ]]\n",
    "    datacp = datacp[-datacp[secNodeCol].isnull()]\n",
    "    datacp[secNodeCol] = le.fit_transform( datacp[secNodeCol] )+ 1000000\n",
    "    each =datacp.groupby([dataID,secNodeCol])[dataID].agg({\"trans_cnt\":'count'}).reset_index()\n",
    "    total = each.groupby(secNodeCol)[\"trans_cnt\"].agg({ 'trans_cnt_total' :\"sum\"}).reset_index()\n",
    "    gp = pd.merge(each,total,on=[ secNodeCol] )\n",
    "    del datacp,each,total\n",
    "    gp[ \"weight\"] = gp['trans_cnt']/gp['trans_cnt_total']\n",
    "    gp = gp.drop(['trans_cnt','trans_cnt_total'],axis = 1)\n",
    "    savename = cacheRoot +  'sourceEmb/{}_weighted_edglist.txt'.format(secNodeCol)\n",
    "    np.savetxt(savename, gp.values, fmt=['%d','%d','%f'])\n",
    "    return savename\n",
    "\n",
    "\n",
    "def createEdgeFomat(fname):\n",
    "    G = nx.Graph()\n",
    "    f = open(fname,'r')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    lines =[l.replace(\"\\n\",\"\").split(\" \")  for l in lines]\n",
    "    lines = [[int(x[0]),int(x[1]),float(x[2])] for x in lines]\n",
    "    edfname = fname.replace(\".txt\",\".edgelist\")\n",
    "    \n",
    "    for edg in lines:\n",
    "        G.add_edge(edg[0], edg[1], weight=edg[2])\n",
    "    print(\"\\n-------------------------------------\\n\")\n",
    "    print(\"saving fali name %s \" % edfname)\n",
    "    print(\"\\n-------------------------------------\\n\")\n",
    "    fh=open(edfname,'wb')\n",
    "    nx.write_edgelist(G, fh)\n",
    "    fh.close()\n",
    "    return edfname\n",
    "\n",
    "\n",
    "def emb_graph_2vec(inputpath,dim):\n",
    "    print(\"input name will be \",inputpath)\n",
    "    emb_name = inputpath.replace(\"weighted_edglist.edgelist\",\"\")\n",
    "    print(\"emb_name will be \",emb_name)\n",
    "\n",
    "    savename =inputpath.replace(\"weighted_edglist.edgelist\",\".emb\")\n",
    "    print(\"emb outfile name will be \",savename)\n",
    "    if os.path.exists(savename):\n",
    "        print(\"file alread exists in cache, please rename\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    graph = nx.read_edgelist(inputpath,create_using=nx.DiGraph())\n",
    "    # Precompute probabilities and generate walks - **ON WINDOWS ONLY WORKS WITH workers=1**\n",
    "    node2vec = Node2Vec(graph, dimensions=dim, walk_length=30,p=0.3, q=1.3, num_walks=200, workers=10 ,weight_key='weight') \n",
    "    # Embed nodes\n",
    "    print(\"training .... \")\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    print(\"training finished saving result... \")\n",
    "\n",
    "    print(\"saving %s file to disk \"%savename)\n",
    "    # Save embeddings for later use\n",
    "    model.wv.save_word2vec_format(savename)\n",
    "    print(\"done\")\n",
    "savename = create_edgelist(his_trans,'card_id','merchant_id' )\n",
    "edfname = createEdgeFomat(savename)\n",
    "emb_graph_2vec(edfname,36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programfiles2\\anaconda\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Computing transition probabilities: 100%|████████████████████████████████████████████| 100/100 [00:01<00:00, 84.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "# Create a graph\n",
    "graph = nx.fast_gnp_random_graph(n=100, p=0.5)\n",
    "\n",
    "# Precompute probabilities and generate walks - **ON WINDOWS ONLY WORKS WITH workers=1**\n",
    "node2vec = Node2Vec(graph, dimensions=64, walk_length=30,p=0.3, q=1.3, num_walks=200, workers=4,weight_key='weight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programfiles2\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dataroot = \"../data/\"\n",
    "cacheRoot = \"../cache/\"\n",
    "\n",
    "\n",
    "trainFiles  = {\"transaction\":'transaction_train_new.csv', \"operation\" :'operation_train_new.csv', \"label\" :'tag_train_new.csv'} \n",
    "validFiles = {\"transaction\":'transaction_round1_new.csv', \"operation\" :'operation_round1_new.csv'}\n",
    "testFiles  = {\"transaction\":'test_transaction_round2.csv', \"operation\" :'test_operation_round2.csv'}\n",
    "\n",
    "\n",
    "# train operation\n",
    "train_oper = pd.read_csv( dataroot + trainFiles['operation'],encoding=\"utf8\")\n",
    "# train transaction\n",
    "train_transac = pd.read_csv( dataroot + trainFiles['transaction'],encoding=\"utf8\")\n",
    "# train tag\n",
    "# test operation\n",
    "test_oper_r1 = pd.read_csv(dataroot + validFiles[\"operation\"],encoding=\"utf8\")\n",
    "# test transaction\n",
    "test_transac_r1 = pd.read_csv(dataroot + validFiles[\"transaction\"],encoding=\"utf8\")\n",
    "\n",
    "test_oper_r2 = pd.read_csv(dataroot + testFiles[\"operation\"],encoding=\"utf8\")\n",
    "# test transaction\n",
    "test_transac_r2 = pd.read_csv(dataroot + testFiles[\"transaction\"],encoding=\"utf8\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oper_tran_grpuse_col = ['UID',\"device1\",\"mac1\",\"ip1\",\"geo_code\", \"device_code1\",\"device_code2\",\"device_code3\" ]\n",
    "oper_col = [ 'UID','ip','ip_sub','wifi' ]# ip  ip1 fillna ip2  ip1_sub fillna ip2_sub\n",
    "tran_col = ['UID', 'merchant', 'code2' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ['ip1','mac1','mac2','geo_code']\n",
    "# ['ip1','mac1','mac2' ,'merchant']\n",
    "oper_tran_grpuse = pd.concat([ train_oper[oper_tran_grpuse_col],test_oper_r1[oper_tran_grpuse_col] , test_oper_r2[oper_tran_grpuse_col],train_transac[oper_tran_grpuse_col],test_transac_r1[oper_tran_grpuse_col],test_transac_r2[oper_tran_grpuse_col]])\n",
    "train_oper['ip']   = train_oper['ip1'].fillna( train_oper['ip2'])\n",
    "test_oper_r1['ip'] = test_oper_r1['ip1'].fillna( test_oper_r1['ip2'])\n",
    "test_oper_r2['ip'] = test_oper_r2['ip1'].fillna( test_oper_r2['ip2'])\n",
    "\n",
    "train_oper['ip_sub']   = train_oper['ip1_sub'].fillna( train_oper['ip2_sub'])\n",
    "test_oper_r1['ip_sub'] = test_oper_r1['ip1_sub'].fillna( test_oper_r1['ip2_sub'])\n",
    "test_oper_r2['ip_sub'] = test_oper_r2['ip1_sub'].fillna( test_oper_r2['ip2_sub'])\n",
    "oper_use = pd.concat([ train_oper,test_oper_r1,test_oper_r2 ])\n",
    "tran_use = pd.concat([ train_transac,test_transac_r1,test_transac_r2 ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programfiles2\\anaconda\\lib\\site-packages\\ipykernel\\__main__.py:11: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "D:\\Programfiles2\\anaconda\\lib\\site-packages\\ipykernel\\__main__.py:12: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sourcedata = [{\"usedata\":oper_tran_grpuse,\"useCol\":oper_tran_grpuse_col},\n",
    "              {\"usedata\":oper_use,\"useCol\":oper_col},\n",
    "              {\"usedata\":tran_use,\"useCol\":tran_col}\n",
    "             ]\n",
    "\n",
    "def create_edgelist(useData, secNodeCol):\n",
    "    le = LabelEncoder()\n",
    "    datacp = useData[[\"UID\",secNodeCol ]]\n",
    "    datacp = datacp[-datacp[secNodeCol].isnull()]\n",
    "    datacp[secNodeCol] = le.fit_transform( datacp[secNodeCol] )+ 1000000\n",
    "    each =datacp.groupby([\"UID\",secNodeCol])['UID'].agg({\"trans_cnt\":'count'}).reset_index()\n",
    "    total = each.groupby(secNodeCol)[\"trans_cnt\"].agg({ 'trans_cnt_total' :\"sum\"}).reset_index()\n",
    "    gp = pd.merge(each,total,on=[ secNodeCol] )\n",
    "    del datacp,each,total\n",
    "    gp[ \"ratio\"] = gp['trans_cnt']/gp['trans_cnt_total']\n",
    "    gp = gp.drop(['trans_cnt','trans_cnt_total'],axis = 1)\n",
    "    savename = cacheRoot +  'sourceEmb/{}_weighted_edglist_filytypeTxt.txt'.format(secNodeCol)\n",
    "    np.savetxt(savename, gp.values, fmt=['%d','%d','%f'])\n",
    "    gp = gp.drop(\"ratio\",axis = 1)\n",
    "    savenameForDeepWalk = cacheRoot +  '{}_weighted_edglist_DeepWalk.txt'.format(secNodeCol)\n",
    "    np.savetxt(savenameForDeepWalk, gp.values, fmt=['%d','%d'])\n",
    "    del gp\n",
    "\n",
    "\n",
    "\n",
    "for spec in sourcedata:\n",
    "    for c in spec[\"useCol\"]:\n",
    "        if c != \"UID\":\n",
    "            create_edgelist(spec[\"usedata\"], c)\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# dict(zip(df['keys'],df['vals'] ))\n",
    "df = pd.DataFrame()\n",
    "keys = ['a','b','c','a']\n",
    "vals = [1,2,3,4]\n",
    "df['keys'] = keys\n",
    "df['vals'] = vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'b': 1, 'c': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "dict(zip(keys,le.fit_transform( keys )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'c': 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(df['keys'],df['vals'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating code2_weighted edge format for node2vec embedding ... \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "saving fali name ./compFeatures/sourceEmb/code2_weighted_edglist_filytypeTxt.edgelist \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "code2_weighted_edglist_filytypeTxt finish\n",
      "creating device1_weighted edge format for node2vec embedding ... \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "saving fali name ./compFeatures/sourceEmb/device1_weighted_edglist_filytypeTxt.edgelist \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "device1_weighted_edglist_filytypeTxt finish\n",
      "creating device_code1_weighted edge format for node2vec embedding ... \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "saving fali name ./compFeatures/sourceEmb/device_code1_weighted_edglist_filytypeTxt.edgelist \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "device_code1_weighted_edglist_filytypeTxt finish\n",
      "creating device_code2_weighted edge format for node2vec embedding ... \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "saving fali name ./compFeatures/sourceEmb/device_code2_weighted_edglist_filytypeTxt.edgelist \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "device_code2_weighted_edglist_filytypeTxt finish\n",
      "creating device_code3_weighted edge format for node2vec embedding ... \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "saving fali name ./compFeatures/sourceEmb/device_code3_weighted_edglist_filytypeTxt.edgelist \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "device_code3_weighted_edglist_filytypeTxt finish\n",
      "creating geo_code_weighted edge format for node2vec embedding ... \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "saving fali name ./compFeatures/sourceEmb/geo_code_weighted_edglist_filytypeTxt.edgelist \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "geo_code_weighted_edglist_filytypeTxt finish\n",
      "creating ip1_weighted edge format for node2vec embedding ... \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "saving fali name ./compFeatures/sourceEmb/ip1_weighted_edglist_filytypeTxt.edgelist \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "ip1_weighted_edglist_filytypeTxt finish\n",
      "creating ip_sub_weighted edge format for node2vec embedding ... \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "saving fali name ./compFeatures/sourceEmb/ip_sub_weighted_edglist_filytypeTxt.edgelist \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "ip_sub_weighted_edglist_filytypeTxt finish\n",
      "creating ip_weighted edge format for node2vec embedding ... \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "saving fali name ./compFeatures/sourceEmb/ip_weighted_edglist_filytypeTxt.edgelist \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "ip_weighted_edglist_filytypeTxt finish\n",
      "creating mac1_weighted edge format for node2vec embedding ... \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "saving fali name ./compFeatures/sourceEmb/mac1_weighted_edglist_filytypeTxt.edgelist \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "mac1_weighted_edglist_filytypeTxt finish\n",
      "creating merchant_weighted edge format for node2vec embedding ... \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "saving fali name ./compFeatures/sourceEmb/merchant_weighted_edglist_filytypeTxt.edgelist \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "merchant_weighted_edglist_filytypeTxt finish\n",
      "creating wifi_weighted edge format for node2vec embedding ... \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "saving fali name ./compFeatures/sourceEmb/wifi_weighted_edglist_filytypeTxt.edgelist \n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "wifi_weighted_edglist_filytypeTxt finish\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "def createEdgeFomat(fname):\n",
    "    G = nx.Graph()\n",
    "    f = open(fname,'r')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    lines =[l.replace(\"\\n\",\"\").split(\" \")  for l in lines]\n",
    "    lines = [[int(x[0]),int(x[1]),float(x[2])] for x in lines]\n",
    "    edfname = fname.replace(\".txt\",\".edgelist\")\n",
    "    \n",
    "    for edg in lines:\n",
    "        G.add_edge(edg[0], edg[1], weight=edg[2])\n",
    "    print(\"\\n-------------------------------------\\n\")\n",
    "    print(\"saving fali name %s \" % edfname)\n",
    "    print(\"\\n-------------------------------------\\n\")\n",
    "    fh=open(edfname,'wb')\n",
    "    nx.write_edgelist(G, fh)\n",
    "    fh.close()\n",
    "\n",
    "for f in os.listdir(cacheRoot):\n",
    "    if \"DeepWalk\" not in f:\n",
    "        print(\"creating %s edge format for node2vec embedding ... \" % (f.replace( \"_edglist_filytypeTxt.txt\", \"\" )) )\n",
    "        createEdgeFomat(cacheRoot + f)\n",
    "        print(f.split(\".\")[0],\"finish\")\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
